{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maMDP.agents import Agent\n",
    "from maMDP.mdp import SquareGridMDP, MDP\n",
    "from maMDP.environments import Environment\n",
    "from maMDP.algorithms.action_selection import SoftmaxActionSelector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an environment\n",
    "\n",
    "The `Environment` class provides a way for any number of agents to act with a Markov Decision Problem (MDP).\n",
    "\n",
    "The first thing we need to do is define an agent, using the `Agent` class. When we define the agent, we need to specify its name, which is used to identify it later on.\n",
    "2. \n",
    "\n",
    "Here we create an agent called `testAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_agent = Agent('testAgent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define the MDP, which is done using the `MDP` class. An MDP here is defined by its transition function, which is implemented as a Numpy array with the shape `n states, n actions, n states` - this represents the result of taking a given action in a given state and can be either deterministic (i.e. taking a given action in a given state leads to a single state with 100% probability) or probabilistic (i.e. taking a given action in a given state can lead to multiple other states with different probabilities). \n",
    "\n",
    "The `MDP` object also contains information about the features associated with each state, represented by a Numpy array with the shape `n features, n states`. The values of this array are arbitrary and will depend on the particular features being implemented.\n",
    "\n",
    "### Standard MDPs\n",
    "\n",
    "Two MDPs are implemented for ease of use - square and hexagonal grids. These allow a grid of a certain shape to be specified easily, without having to specificy the transition function manually.\n",
    "\n",
    "Here we'll use a square grid, using the `SquareGridMDP` class. We'll give it a shape of 15 x 15 cells, and place the first feature in one corner of the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_shape = (15, 15)\n",
    "\n",
    "# Create an array representing the two features\n",
    "features = np.zeros((2, np.product(grid_shape)))\n",
    "\n",
    "# The first feature is placed in the bottom right corner of the grid. The second feature isn't present.\n",
    "features[0, 220:] = 1\n",
    "features[0, 205:210] = 1\n",
    "\n",
    "new_mdp = SquareGridMDP(shape=grid_shape, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we wrap our agent and our MDP together using the `Environment` class. \n",
    "\n",
    "When creating the object, the first argument we pass is the `MDP` object we just created. The second argument is a dictionary which specifies the agents we want to use and their starting positions. Keys represent `Agent` objects, while values represent three values relating to how the agent interacts with the MDP, supplies as a 3-tuple. These are:\n",
    "1. The starting position of the agent (representing the state we want to start it in).\n",
    "2. Its reward function for the MDP it's going to be interacting with. This is specified as a list with an entry corresponding to each feature in the MDP, plus an entry for each agent (including itself). This means that the agent can value not only the static features in the environment, but also the agents in the environment. The higher the number, the greater the value of that feature.\n",
    "3. Which features it consumes when it encounters them - i.e. if a state contains a feature, does it disappear from that state if the agent enters it.\n",
    "\n",
    "For this example, we're going to place our single agent (`new_agent`) in the environment, starting it at state #2. Its reward function places a weight of `1` on the first feature in the environment, `0` on the second feature and a value of `0` for the only agent in the environment (itself). It doesn't consume any features, as indicated by an empty list (`[]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_env = Environment(new_mdp, {new_agent: (2, [1, 0, 0], [])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the environment\n",
    "\n",
    "The `Environment` class implements methods for plotting the environment, which we can use to see what we've created.\n",
    "\n",
    "> **_Note:_**  When calling the plotting methods of the `Environment` class, this in turn calls methods implemented in the `MDP` class. Plotting will differ depending on the type of MDP, and appropriate methods will need to be implemented for any custom MDPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14dac369310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_env.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 200}, agent_colours={'testAgent': '#bd4848'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our agent has appeared in the top left of the grid, while our feature is present in the bottom right corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the MDP\n",
    "\n",
    "Each agent is able to interact with the associated MDP. Generally, we will want to figure out the best action to take in the current state, and then take that action to move the agent to the subsequent state.\n",
    "\n",
    "First, we need to figure out the best state to move to next. To achieve this, the `Agent` class has a `.fit()` method, which will determine the best action from the current state. This happens in two steps:\n",
    "\n",
    "### Calculating action values\n",
    "First, action values are calculated. By default, the agent will use value iteration to solve the MDP and calculate Q values for each action. This can be changed by changing the value passed to the `algorithm` argument when creating the `Agent`.\n",
    "\n",
    "### Selecting an action\n",
    "Given the calculated Q values, actions can then be chosen using any decision rule. By default, the agent will use the max rule - that is, taking the action with the highest Q value. This is set by passing a different action selector to the `action_selector` argument when creating the `Agent`. \n",
    "\n",
    "To fit the agent, rather than calling the agent's own `.fit()` method, we can use the `.fit()` method of the environment and specify the agent we wish to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_env.fit('testAgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21576652, 1.21576652, 0.98477087, 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_env.agents['testAgent'].algorithm.q_values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_env.get_agent_pi('testAgent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've figured out the best action to take, we can move the agent. This can be done using the `.step()` method of the environment, again specifying the agent we want to move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14dadac1580>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_env.step('testAgent')\n",
    "new_env.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 200}, agent_colours={'testAgent': '#bd4848'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the agent has now moved down one cell.\n",
    "\n",
    "Often we will want to move more than one step at a time. Assuming the MDP has been solved (i.e. we have Q values for every action in every state), we can use the `.step_multi()` method to achieve this by supplying the agent we wish to move and the number of steps we want to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14dae2e1490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_env.step_multi('testAgent', 25)\n",
    "new_env.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 200}, agent_colours={'testAgent': '#bd4848'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our agent has now moved to the bottom right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting trajectories\n",
    "\n",
    "It's often useful to be able to see the states the agent has visited during its travels.\n",
    "\n",
    "First, we can get the agent's history of states visited using the `.get_agent_position_history()` method. We can plot this using the `.plot_trajectory()` method (assuming the `MDP` being used has methods to plot trajectories implemented)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajectory = new_env.get_agent_position_history('testAgent')\n",
    "\n",
    "# First plot the environment\n",
    "ax = new_env.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 300})\n",
    "\n",
    "# Add the trajectory\n",
    "new_env.plot_trajectory(trajectory, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting state values\n",
    "\n",
    "Algorithms used to solve the MDP will typically estimate the value function for the MDP, and we can also plot this using the `.plot_state_values()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = new_env.plot_state_values('testAgent', figsize=(15, 5))\n",
    "new_env.plot_trajectory(trajectory, ax, colour='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetting the environment\n",
    "\n",
    "To reset the environment back to its starting state, we use the `.reset()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14dadb575e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_env.reset()\n",
    "new_env.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 200}, agent_colours={'testAgent': '#bd4848'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming features\n",
    "\n",
    "We can repeat this with an agent that consumes features as it comes across them.\n",
    "\n",
    "With the following specification, the agent will new consume the first feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_agent = Agent('testAgent')\n",
    "new_mdp = SquareGridMDP(shape=grid_shape, features=features)\n",
    "new_env_consume = Environment(new_mdp, {new_agent: (2, [1, 0, 0], [0])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we solve the MDP and move the agent around, we can see that the feature has disappeared from the states the agent has visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_env_consume.fit('testAgent')\n",
    "new_env_consume.step_multi('testAgent', 25)\n",
    "\n",
    "trajectory = new_env_consume.get_agent_position_history('testAgent')\n",
    "\n",
    "# First plot the environment\n",
    "ax = new_env_consume.plot(mdp_plotting_kwargs={'figsize': (15, 5)}, agent_plotting_kwargs={'s': 300})\n",
    "\n",
    "# Add the trajectory\n",
    "new_env_consume.plot_trajectory(trajectory, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how much of each feature the agent has consumed - this is useful for determining how much reward an agent has gained, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_env_consume.agents['testAgent'].consumed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
